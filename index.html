<!DOCTYPE HTML>

<style>
  #full {
    display: none;
  }
  </style>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xinzhou Wang</title>
  
  <meta name="author" content="Xinzhou Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>


<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xinzhou Wang | 王心舟</name>
              </p>
              <p> 
                I am a third-year PhD student at CEIE, Tongji University and Department of Computer Science, Tsinghua University, 
                  advised by Prof. Fuchun Sun</a>. 
                  I obtained my B.S. and M.S at Beihang University.
              </p>
              <p>
                My research interest lies in the <b>3D Generation</b> and <b>3D Reconstruction</b>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:wangxinzhou.buaa@foxmail.com">Email</a> &nbsp/&nbsp
                <a href="https://zz7379.github.io/">CV</a> &nbsp/&nbsp
                <a href="https://zz7379.github.io/"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/zz7379"> Github </a>
              </p>
            </td>
            <td style="padding:3%;width:40%;max-width:40%">
              <img style="width:70%;max-width:70%" alt="profile photo" src="images/wxz2.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p><heading>Publications</heading></p>
              <p>
                * indicates equal contribution
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/pipeline2.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>AnimatableDreamer: Text-Guided Non-rigid 3D Model Generation 
                and Reconstruction with Canonical Score Distillation</papertitle>
              <br>
              <strong>Xinzhou Wang</strong>,
              Yikai Wang,
              Junliang Ye, 
              Zhengyi Wang,
              Fuchun Sun,
              Pengkun Liu,
              Ling Wang,
              Kai Sun, 
              Xintong Wang, 
              Bin He
              <br>
              <em>ECCV, 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2312.03795">[arXiv]</a>
              <a href="https://github.com/AnimatableDreamer/AnimatableDreamer">[Code]</a>
              <a href="https://zz7379.github.io/AnimatableDreamer">[Project Page]</a> 
              <br>
              <p> We propose AnimatableDreamer, a framework with the capability to generate generic categories of non-rigid 3D models.</p>
            </td>
          </tr>
          

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/pipeline.jpg" alt="dise">
            </td>
            <td width="80%" valign="center">
              <papertitle>DreamReward: Aligning Human Preference in Text-to-3D Generation</papertitle>
              <br>
              Junliang Ye*, 
              Fangfu Liu*, 
              Qixiu Li,
              Zhengyi Wang,
              Yikai Wang,
              <strong>Xinzhou Wang</strong>,
              Yueqi Duan </a>,
              Jun Zhu
              <br>
              <em>ECCV, 2024</em>
              <br>
              <a href="http://arxiv.org/abs/2403.14613">[arXiv]</a>
              <a href="https://github.com/liuff19/DreamReward">[Code]</a>
              <a href="https://jamesyjl.github.io/DreamReward/">[Project Page]</a> 
              <br>
              <p> We present a comprehensive framework, coined DreamReward, to 
                learn and improve text-to-3D models from human preference feedback.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/pipeline_iso.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding</papertitle>
              <br>
              Pengkun Liu, Yikai Wang, Fuchun Sun, Jiafang Li, Hang Xiao, Hongxiang Xue, <strong>Xinzhou Wang</strong>
              <br>
              <em>Arxiv, 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2403.10395">[arXiv]</a>
              <a href="https://isotropic3d.github.io/">[Code]</a>
              <a href="https://github.com/pkunliu/Isotropic3D">[Project Page]</a> 
              <br>
              <p> We propose Isotropic3D, an image-to-3D generation pipeline that takes only an image CLIP embedding as input.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/tongue.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Deep Learning Based Tongue Prickles Detection in Traditional Chinese Medicine</papertitle>
              <br>
              <strong>Xinzhou Wang</strong>, Siyan Luo, Guihua Tian, Xiangrong Rao, Bin He, Fuchun Sun
              <br>
              <em>Evidence-Based Complementary and Alternative Medicine, 2022</em>
              <br>
              <a href="https://www.hindawi.com/journals/ecam/2022/5899975/">[Paper]</a>
              <br>
              <p> We provides a quantitative perspective for symptoms and disease diagnosis according to tongue characteristics.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:80%;max-width:80%" src="images/engine.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Measurement Selection Method for Aero-engine Discrete Operating Conditions Gas Path Analysis</papertitle>
              <br>
              Xintong Wang, <strong>Xinzhou Wang</strong>
              <br>
              <em>International Conference on Algorithms, Data Mining, and Information Technology (ADMIT), 2022</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9974728">[Paper]</a>
              <br>
              <p> We provides a method for measurement selection of Aero-engine gas path analysis.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:80%;max-width:80%" src="images/cos.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Camouflaged Object Segmentation with Transformer</papertitle>
              <br>
              Haiwen Wang*, <strong>Xinzhou Wang*</strong>, Fuchun Sun, Yixu Song
              <br>
              <em> Cognitive Systems and Information Processing, 2021</em>
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-981-16-9247-5_17">[Paper]</a>
              <br>
              <p> We provides a transformer for camouflaged object segmentation.</p>
            </td>
          </tr>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                Review for <b>CVPR 2023</b>.
              </li>
          </td>
        </tr> -->
      </tbody></table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=0E8MTgY3uzPlMqQ6k4ja-Y8ajcyDF48Pd6VYZ5EfX_A"></script>
	  <br>
	    &copy; Xinzhou Wang | Last updated: 25 Mar, 2024
</center></p>
</body>

</html>
